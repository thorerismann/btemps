{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57edc566-ed88-4e94-85f4-448f8c343a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code set-up\n",
    "\n",
    "# Import statements\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime as dt\n",
    "\n",
    "# Directories for reading and writing data\n",
    "thedir = os.getcwd()\n",
    "writedir = os.path.abspath(os.path.join(os.path.dirname(thedir), '..', 'data/interim'))\n",
    "extdir = os.path.abspath(os.path.join(os.path.dirname(thedir), '..', 'data/external'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3112ed4e-4a98-4f46-9fd6-958be79ae8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data files\n",
    "# I have commented out the unneeded analysis for this application to the Bern 2018 data\n",
    "\n",
    "# Data from Biel July 2022\n",
    "#data_lcd = pd.read_csv(F'{writedir}/alldata.csv')\n",
    "\n",
    "# data from closesent OpenSenseMap sensor (Brügg) here: https://familie-hoffmann.me/ \n",
    "# data_os = pd.read_csv(F'{extdir}/opensense-temp.csv')\n",
    "\n",
    "# data with metadata from 2018 Bern Stadtklima study\n",
    "data_be = pd.read_csv(F'{extdir}/2018_Stadtklimamessnetz_Rohdaten.csv')\n",
    "data_be_meta = pd.read_csv(F'{extdir}/2018_Stadtklimamessnetz_Metadaten.csv')\n",
    "\n",
    "# data without metadata from select stations\n",
    "data_test = pd.read_csv(F'{extdir}/ref_2018.csv')\n",
    "\n",
    "# archival mean data 1983\n",
    "#archive_ = pd.read_csv(F\"{writedir}/archive_1983.csv\")\n",
    "#archive_.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# key names that describe the choice\n",
    "# load dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef60fcf4-2161-4377-94e3-84c80eaca797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data corrections to fit into class objects. This is unique to each data set.\n",
    "\n",
    "# metadata correction for Bern\n",
    "# this block makes the metadata for the bern sensors easily readable into the class as dicts later on\n",
    "def make_logger(x):\n",
    "    data = 'Log_' + str(x)\n",
    "    return data\n",
    "\n",
    "def make_str(x):\n",
    "    return str(x)\n",
    "\n",
    "def get_city(x):\n",
    "    if \"Zoll\" in x:\n",
    "        return \"Zollikofen\"\n",
    "    elif \"Uett\" in x:\n",
    "        return \"Uettligen\"\n",
    "    else:\n",
    "        return \"Bern\"\n",
    "\n",
    "data_be_meta['logger'] = data_be_meta.LogNr_2018.apply(lambda x: make_logger(x))\n",
    "data_be_meta['gps_lat'] = data_be_meta.NORD_CHTOPO.apply(lambda x: make_str(x))\n",
    "data_be_meta['gps_lon'] = data_be_meta.OST_CHTOPO.apply(lambda x: make_str(x))\n",
    "data_be_meta['coord'] = '(' + data_be_meta.gps_lat + ',' + data_be_meta.gps_lon + ')'\n",
    "data_be_meta.set_index('logger',inplace=True)\n",
    "data_be_meta = data_be_meta[['coord','Name','ELEV_CHTOPO']].copy()\n",
    "data_be_meta['city'] = data_be_meta.Name.apply(lambda x: get_city(x))\n",
    "\n",
    "# correct date-time column for each set of loaded data\n",
    "\n",
    "def fix_date_string(x):\n",
    "    x = x[:10] + \" \" + x[11:-5]\n",
    "    return x\n",
    "\n",
    "#data_os['time_int'] = data_os.createdAt.apply(lambda x: fix_date_string(x))\n",
    "#data_os['md'] = pd.to_datetime(data_os.time_int,format = '%Y/%m/%d %H:%M:%S')\n",
    "#data_lcd[\"md\"] = pd.to_datetime(data_lcd.time,format = '%Y/%m/%d %H:%M:%S')\n",
    "data_be['md'] = pd.to_datetime(data_be['Zeit'], infer_datetime_format=True)\n",
    "#archive_['md'] = pd.to_datetime(archive_['index'], infer_datetime_format=True)\n",
    "data_test['md'] = pd.to_datetime(data_test['Date_time_CET'], infer_datetime_format=True)\n",
    "\n",
    "# split data for data test into low cost device and automatic weather stations\n",
    "data_aws = data_test[['BOLL_AWS_TEMP', 'BOLL_PRECIP', 'BOLL_RADIATION_GLOBAL', 'BOLL_WIND_SPEED_mean','ZOLL_AWS_TEMP', 'ZOLL_RADIATION_GLOBAL', 'ZOLL_SUNSHINE', 'ZOLL_PRECIP', \n",
    "                   'ZOLL_WIND_SPEED_MEAN','AFU_AWS_TEMP', 'AFU_WIND_SPEED_MEAN', 'AFU_RADIATION_GLOBAL','md']]\n",
    "data_lcd = data_test[['BOLL_LCD_TEMP','ZOLL_2m_LCD_TEMP',\n",
    "       'ZOLL_3m_LCD_TEMP','md','AFU_LCD_TEMP','ZOLL_STEVENSON_LCD_TEMP']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f786611-c4eb-4238-95a2-7fe056804dea",
   "metadata": {},
   "source": [
    "## Create sensor classes\n",
    "This section reads in the sensor classes by chunk of data (biel data, bern data, archive_ data, opensensor data, reference data)\n",
    "\n",
    "Note that the variables are instatiated as `None` as default\n",
    "\n",
    "There is a base `Sensor` Class and four subclasses: `LowCostSensors AutoSensors OpenSensors archive_Sensors`\n",
    "\n",
    "The class `LowCostSensors` is for the LCD sensors that this study is based around. `AutoSensors` are for the automatic weather station data. `OpenSensors` is for readings from the OpenSenseMap network. `archive_Sensors` are for data from the archive_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c60076b-4556-4d85-92ed-699b22864cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base sensor class inherited by the different sensor type subclasses\n",
    "class Sensors(object):\n",
    "    def __init__(self, project=None, year=None, name=None, city=None, sensor_type=None, data = None, qty=None, elev=None, coord=None, quant = None):\n",
    "        self.project = project\n",
    "        self.year = year\n",
    "        self.name = name\n",
    "        self.city = city\n",
    "        self.data = data\n",
    "        self.qty = qty\n",
    "        self.sensor_type = sensor_type\n",
    "        self.coord = coord\n",
    "        self.elev = elev\n",
    "        self.quant = quant\n",
    "    def get_month(self):\n",
    "        x = self.data\n",
    "        x['month'] = x.md.dt.to_period(\"m\")\n",
    "        return x\n",
    "    def get_year(self):\n",
    "        x = self.data\n",
    "        x['year'] = x.md.dt.to_period(\"y\")\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9372e9f-ad3f-4a17-afcb-aec637cf5aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the two sensors class used here correspond to the AWS sensors and the LCD sensors\n",
    "\n",
    "class AutoSensors(Sensors):\n",
    "    ## date time functions\n",
    "    def get_day(self):\n",
    "        x = self.data\n",
    "        x['day'] = x.md.dt.to_period(\"d\")\n",
    "        return x\n",
    "    \n",
    "    ## basic stats functions\n",
    "    def get_mean(self,time):\n",
    "        x = self.data\n",
    "        print(x.head())\n",
    "        data = x.groupby([time]).agg('mean')\n",
    "        return data\n",
    "    def get_max(self,time):\n",
    "        x = self.data\n",
    "        print(x.head())\n",
    "        data = x.groupby([time]).agg('max')\n",
    "        a = data.copy()\n",
    "        return a\n",
    "    def get_min(self,time):\n",
    "        x = self.data\n",
    "        data = x.groupby([time]).agg('min')\n",
    "        return data\n",
    "    def get_var(self,time):\n",
    "        x = self.data\n",
    "        data = x.groupby([time]).agg('var')\n",
    "        return data\n",
    "\n",
    "class LowCostSensors(Sensors):\n",
    "    \n",
    "    ## date time functions\n",
    "    def get_day(self):\n",
    "        x = self.data\n",
    "        x['day'] = x.md.dt.to_period(\"d\")\n",
    "        return x\n",
    "    \n",
    "    ## basic stats functions\n",
    "    def get_mean(self,time):\n",
    "        x = self.data\n",
    "        data = x.groupby([time]).agg('mean')\n",
    "        a = [x for x in data.columns if x[:3] == \"Log\"]\n",
    "        return data[a]\n",
    "    def get_max(self,time):\n",
    "        x = self.data\n",
    "        data = x.groupby([time]).agg('max')\n",
    "        a = [x for x in data.columns if x[:3] == \"Log\"]\n",
    "        return data[a]\n",
    "    def get_min(self,time):\n",
    "        x = self.data\n",
    "        data = x.groupby([time]).agg('min')\n",
    "        a = [x for x in data.columns if x[:3] == \"Log\"]\n",
    "        return data[a]\n",
    "    def get_var(self,time):\n",
    "        x = self.data\n",
    "        data = x.groupby([time]).agg('var')\n",
    "        a = [x for x in data.columns if x[:3] == \"Log\"]\n",
    "        return data[a]\n",
    "    \n",
    "    ## elevation and height corrections and Swiss Meteo corrections\n",
    "    \n",
    "    ## Radiation\n",
    "    \n",
    "    ## humidity\n",
    "    \n",
    "    # homogenization with Swiss meteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "737e6242-9696-4785-b521-b53a313bf70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in opensensor\n",
    "#os_1 = OpenSensors('OpenSense',2022,'Gumme Brügg','Brügg','custom',data_os,'Temperature',469,(47.126465,7.285249))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f38b11c-fa77-4518-8a8e-9a2fe854bc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in Biel Sensors\n",
    "elevation= {\"Log_202\":430, \"Log_201\":432,\"Log_203\":433,\"Log_204\":430,\"Log_205\":439,\"Log_206\":437,\"Log_207\":430}\n",
    "coord= {\"Log_202\":(47.130669,7.236258), \"Log_201\":(47.130792,7.241046),\"Log_203\": (47.136637, 7.246960),\"Log_204\":(47.141086,7.253485),\"Log_205\":(47.144746,7.265149),\"Log_206\":(47.138338,7.295326),\"Log_207\":(47.179081,7.415102)}\n",
    "city= {\"Log_202\":'Biel', \"Log_201\":'Biel',\"Log_203\":'Biel',\"Log_204\":'Biel',\"Log_205\":'Biel',\"Log_206\":'Orpund',\"Log_207\":'Grenchen'}\n",
    "\n",
    "log_cols = [ x for x in data_lcd.columns if x[:3] == \"Log\" ]\n",
    "\n",
    "mylist = []\n",
    "for i in log_cols:\n",
    "    data = data_lcd[['md',i]].copy()\n",
    "    mylist.append(LowCostSensors('biel-temps',2022,i,city[i],'lcd',data,'Temperature',elevation[i],coord[i]))\n",
    "biel_sensors = mylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d6afb41-4de9-42e1-905d-f3bcd8234e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in bern sensors for 2018\n",
    "\n",
    "## Log 64 and Log 63 do not correspond in metadata and data files for bern 2021\n",
    "\n",
    "# checking dict keys\n",
    "#a = data_be.columns\n",
    "#b = data_be_meta.index\n",
    "#mylist = []\n",
    "#for x in a:\n",
    "#    if x not in b:\n",
    "#        mylist.append(x)\n",
    "#    else:\n",
    "#        mylist.append(\"OK\")\n",
    "\n",
    "# uncomment to correct bern 2021 metadata document        \n",
    "data_be['Log_63'] = data_be['Log_64']\n",
    "data_be.drop(['Log_64'],axis = 1,inplace=True)\n",
    "data_be['Log_83'] = data_be['Log_83_REF_AFU_3m']\n",
    "data_be['Log_98'] = data_be['Log_98_REF_ZOLL_2m']\n",
    "data_be['Log_99'] = data_be['Log_99_ZOLL_3m']\n",
    "data_be['Log_999'] = data_be['Log_999_REF_ZOLL_HAUS']\n",
    "data_be.drop(['Log_83_REF_AFU_3m','Log_98_REF_ZOLL_2m','Log_99_ZOLL_3m','Log_999_REF_ZOLL_HAUS'],axis = 1,inplace=True)\n",
    "\n",
    "log_cols = [ x for x in data_be.columns if x[:3] == \"Log\" ]\n",
    "data_be_meta\n",
    "dict_city = data_be_meta['city'].to_dict()\n",
    "dict_coord = data_be_meta['city'].to_dict()\n",
    "dict_elev = data_be_meta['city'].to_dict()\n",
    "mylist = []\n",
    "for i in log_cols:\n",
    "    data = data_be[['md',i]].copy()\n",
    "    mylist.append(LowCostSensors('bern-temps',2021,i,dict_city[i],'lcd',data,'Temperature',dict_elev[i],dict_coord[i]))\n",
    "bern_sensors = mylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2117cef7-80bf-4204-a940-ba73c893a714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in archive_ sensors\n",
    "#elevation = {'mai':720, 'vog':544, 'boz':441}\n",
    "#coord = {'mai':(47.145999,7.242621), 'vog': (47.12456,7.242723), 'boz': (47.15189,7.272195)}\n",
    "#city = {'mai':'evilard', 'vog':'biel', 'boz':'biel'}\n",
    "\n",
    "#lgm = [ x for x in archive_.columns if \"mai\" in x]\n",
    "#lgv = [ x for x in archive_.columns if \"vog\" in x]\n",
    "#lgb = [ x for x in archive_.columns if \"boz\" in x]\n",
    "#lgm.append('md')\n",
    "#lgv.append('md')\n",
    "#lgb.append('md')\n",
    "\n",
    "#cols = [lgm,lgv,lgb]\n",
    "\n",
    "#mylist = []\n",
    "#for i in cols:\n",
    "#    data = archive_[i].copy()\n",
    "#    if 'mai' in i[0]:\n",
    "#        key = 'mai'\n",
    "#        mylist.append(archive_Sensors('archive_',1983,key,city[key],'lcd',data,'Temperature',elevation[key],coord[key]))\n",
    "#    elif 'boz' in i[0]:\n",
    "#        key = 'boz'\n",
    "#        mylist.append(archive_Sensors('archive_',1983,key,city[key],'lcd',data,'Temperature',elevation[key],coord[key]))\n",
    "#    elif 'vog' in i[0]:\n",
    "#        key = 'vog'\n",
    "#        mylist.append(archive_Sensors('archive_',1983,key,city[key],'lcd',data,'Temperature',elevation[key],coord[key]))\n",
    "#archival = mylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47108f03-0ad5-445d-b122-e0713e8c610d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# read in bern aws data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m log_cols_z \u001b[38;5;241m=\u001b[39m [ x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdata_\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m x[:\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZOL\u001b[39m\u001b[38;5;124m\"\u001b[39m ]\n\u001b[1;32m      3\u001b[0m log_cols_b \u001b[38;5;241m=\u001b[39m [ x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data_\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m x[:\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBOL\u001b[39m\u001b[38;5;124m\"\u001b[39m ]\n\u001b[1;32m      4\u001b[0m log_cols_a \u001b[38;5;241m=\u001b[39m [ x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data_\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m x[:\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAFU\u001b[39m\u001b[38;5;124m\"\u001b[39m ]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_' is not defined"
     ]
    }
   ],
   "source": [
    "# read in bern aws data\n",
    "log_cols_z = [ x for x in data_.columns if x[:3] == \"ZOL\" ]\n",
    "log_cols_b = [ x for x in data_.columns if x[:3] == \"BOL\" ]\n",
    "log_cols_a = [ x for x in data_.columns if x[:3] == \"AFU\" ]\n",
    "a = [log_cols_z,log_cols_b,log_cols_a]\n",
    "mylist = []\n",
    "for j in a:\n",
    "    for i in j:\n",
    "        data = data_[['md',i]].copy()\n",
    "        if 'TEMP' in i:\n",
    "            mylist.append(AutoSensors('bern-refs',2018,i,'Bern','lcd',data,'Temperature'))\n",
    "        elif 'WIND' in i:\n",
    "            mylist.append(AutoSensors('bern-refs',2018,i,'Bern','lcd',data,'Wind_Speed'))\n",
    "        elif 'PRECIP' in i:\n",
    "            mylist.append(AutoSensors('bern-refs',2018,i,'Bern','lcd',data,'Precipitation'))\n",
    "        elif 'RADI' in i:\n",
    "            mylist.append(AutoSensors('bern-refs',2018,i,'Bern','lcd',data,'Radiation'))\n",
    "        elif 'SUNS' in i:\n",
    "            mylist.append(AutoSensors('bern-refs',2018,i,'Bern','lcd',data,'Sunshine'))\n",
    "        \n",
    "aws_sensors = mylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc760172-6c8b-4038-abeb-db913305c889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get month and day columns for aggregation\n",
    "[ x.get_month() for x in archival ]\n",
    "[ x.get_month() for x in biel_sensors ]\n",
    "[ x.get_day() for x in biel_sensors ]\n",
    "[ x.get_month() for x in bern_sensors ]\n",
    "[ x.get_day() for x in bern_sensors ]\n",
    "[ x.get_month() for x in aws_sensors ]\n",
    "[ x.get_day() for x in aws_sensors ]\n",
    "#os_1.get_month()\n",
    "#os_1.get_day()\n",
    "x = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e747d446-2a12-48f2-b09e-7440abc81ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_day = [x.get_mean('day') for x in bern_sensors]\n",
    "max_day = [x.get_max('day') for x in bern_sensors]\n",
    "min_day = [x.get_min('day') for x in bern_sensors]\n",
    "\n",
    "mean_day_a = [x.get_mean('day') for x in aws_sensors]\n",
    "max_day_a = [x.get_max('day') for x in aws_sensors]\n",
    "min_day_a = [x.get_min('day') for x in aws_sensors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b658ac22-cb48-4d4f-85f9-9a8898ae1653",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_sensors[2].get_max('month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acddd3d0-08aa-4c71-9438-1382accdf2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_sensors[0].get_max('month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd368927-d767-43ee-8f41-8328e3abc39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plottable(x):\n",
    "    data = pd.concat(x,axis = 1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93d3abf-b8e4-4bc2-8096-2bdc77b05176",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = make_plottable(max_day_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c111be8e-83eb-4b14-93b6-a73f948b9676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1267e5-6c09-4a49-8102-bab9fc2e1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_day[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd773d64-e320-43f0-b173-983e178d4e88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b962b566-7d00-4fa9-a9a2-59064445e609",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mas-clas",
   "language": "python",
   "name": "master-class"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
