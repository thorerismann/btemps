{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23c167bc-98c9-4584-80a9-529fa3e03fcd",
   "metadata": {},
   "source": [
    "# First analysis of raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd107b2f-0f72-43ec-bc24-614795674433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.ticker import AutoLocator\n",
    "\n",
    "# load directories for reading/writing files\n",
    "thedir = os.getcwd()\n",
    "datadir_1 = os.path.abspath(os.path.join(os.path.dirname(thedir), '..', 'data/raw/2022-1'))\n",
    "datadir_2 = os.path.abspath(os.path.join(os.path.dirname(thedir), '..', 'data/raw/2022-2'))\n",
    "writedir = os.path.abspath(os.path.join(os.path.dirname(thedir), '..', 'data/interim'))\n",
    "figdir=os.path.abspath(os.path.join(os.path.dirname(thedir), '..', 'figures'))\n",
    "\n",
    "# get list of files and number of files to load\n",
    "files_1 = os.listdir(datadir_1)\n",
    "files_2 = os.listdir(datadir_2)\n",
    "loggers=len(files_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa1408c2-f224-4abd-ade9-cce567d8755a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Log_204.csv',\n",
       " 'Log_201.csv',\n",
       " 'Log_207.csv',\n",
       " 'Log_205.csv',\n",
       " 'Log_203.csv',\n",
       " 'Log_202.csv',\n",
       " 'Log_206.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca7d273a-f70e-4902-8f56-f3ebc3632062",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_1 = []\n",
    "for i in files_1:\n",
    "    try:\n",
    "        a = pd.read_csv(F\"{datadir_1}/{i}\",header =1)\n",
    "        log = i[:7]\n",
    "        a = a.iloc[:,[1,2]]\n",
    "        mapping = {a.columns[0]: F'dt',a.columns[1]:log}\n",
    "        a.rename(columns=mapping,inplace = True)\n",
    "        a.set_index('dt',inplace=True,drop=True)\n",
    "        obs_1.append(a)\n",
    "    except:\n",
    "        \"not a real file\"\n",
    "obs_2 = []\n",
    "for i in files_1:\n",
    "    try:\n",
    "        a = pd.read_csv(F\"{datadir_2}/{i}\",header =1)\n",
    "        log = i[:7]\n",
    "        a = a.iloc[:,[1,2]]\n",
    "        mapping = {a.columns[0]: F'dt',a.columns[1]:log}\n",
    "        a.rename(columns=mapping,inplace = True)\n",
    "        a.set_index('dt',inplace=True,drop=True)\n",
    "        obs_2.append(a)\n",
    "    except:\n",
    "        \"not a real file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdbbbc35-2492-4bbe-931d-f1eed861064f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(obs_1)-1):\n",
    "    if i == 0:\n",
    "        df_1 = pd.merge_ordered(left = obs_1[0],right = obs_1[1],how = 'outer',fill_method= None,on = 'dt')\n",
    "    else:\n",
    "        df_1 = pd.merge_ordered(left = df_1,right = obs_1[i+1],how = 'outer',fill_method= None,on = 'dt')\n",
    "for i in range(len(obs_2)-1):\n",
    "    if i == 0:\n",
    "        df_2 = pd.merge_ordered(left = obs_2[0],right = obs_2[1],how = 'outer',fill_method= None,on = 'dt')\n",
    "    else:\n",
    "        df_2 = pd.merge_ordered(left = df_2,right = obs_2[i+1],how = 'outer',fill_method= None,on = 'dt')\n",
    "df_1['dt'] = pd.to_datetime(df_1.dt,format = '%d/%m/%y %H:%M:%S')\n",
    "df_2['dt'] = pd.to_datetime(df_2.dt,format = '%d/%m/%y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d03ebfb0-e4f1-4427-b377-5643034cd089",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.sort_values('dt',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "281bb345-33b0-4f15-9fee-3a21b3b4863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.sort_values('dt',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe11dec8-7910-483b-91df-71005721ebc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.set_index('dt',inplace=True,drop=True)\n",
    "df_2.set_index('dt',inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32f114dd-e08c-49e2-bcf8-a75449e204d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Log_204</th>\n",
       "      <th>Log_201</th>\n",
       "      <th>Log_207</th>\n",
       "      <th>Log_205</th>\n",
       "      <th>Log_203</th>\n",
       "      <th>Log_202</th>\n",
       "      <th>Log_206</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-07-09 00:00:00</th>\n",
       "      <td>18.996</td>\n",
       "      <td>20.329</td>\n",
       "      <td>18.426</td>\n",
       "      <td>19.567</td>\n",
       "      <td>20.710</td>\n",
       "      <td>20.329</td>\n",
       "      <td>15.378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-09 00:10:00</th>\n",
       "      <td>18.806</td>\n",
       "      <td>20.234</td>\n",
       "      <td>17.570</td>\n",
       "      <td>19.377</td>\n",
       "      <td>20.615</td>\n",
       "      <td>20.234</td>\n",
       "      <td>14.517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-09 00:20:00</th>\n",
       "      <td>18.616</td>\n",
       "      <td>20.043</td>\n",
       "      <td>16.427</td>\n",
       "      <td>19.282</td>\n",
       "      <td>20.615</td>\n",
       "      <td>20.138</td>\n",
       "      <td>13.942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-09 00:30:00</th>\n",
       "      <td>18.616</td>\n",
       "      <td>20.043</td>\n",
       "      <td>15.951</td>\n",
       "      <td>18.331</td>\n",
       "      <td>20.424</td>\n",
       "      <td>20.043</td>\n",
       "      <td>13.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-09 00:40:00</th>\n",
       "      <td>18.426</td>\n",
       "      <td>19.948</td>\n",
       "      <td>14.900</td>\n",
       "      <td>18.140</td>\n",
       "      <td>20.329</td>\n",
       "      <td>19.853</td>\n",
       "      <td>14.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-14 10:40:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.473</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-14 10:50:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.855</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-14 11:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-14 11:10:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.812</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-14 11:20:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5269 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Log_204  Log_201  Log_207  Log_205  Log_203  Log_202  \\\n",
       "dt                                                                          \n",
       "2022-07-09 00:00:00   18.996   20.329   18.426   19.567   20.710   20.329   \n",
       "2022-07-09 00:10:00   18.806   20.234   17.570   19.377   20.615   20.234   \n",
       "2022-07-09 00:20:00   18.616   20.043   16.427   19.282   20.615   20.138   \n",
       "2022-07-09 00:30:00   18.616   20.043   15.951   18.331   20.424   20.043   \n",
       "2022-07-09 00:40:00   18.426   19.948   14.900   18.140   20.329   19.853   \n",
       "...                      ...      ...      ...      ...      ...      ...   \n",
       "2022-08-14 10:40:00      NaN      NaN   21.473      NaN      NaN      NaN   \n",
       "2022-08-14 10:50:00      NaN      NaN   21.855      NaN      NaN      NaN   \n",
       "2022-08-14 11:00:00      NaN      NaN   23.100      NaN      NaN      NaN   \n",
       "2022-08-14 11:10:00      NaN      NaN   22.812      NaN      NaN      NaN   \n",
       "2022-08-14 11:20:00      NaN      NaN   23.004      NaN      NaN      NaN   \n",
       "\n",
       "                     Log_206  \n",
       "dt                            \n",
       "2022-07-09 00:00:00   15.378  \n",
       "2022-07-09 00:10:00   14.517  \n",
       "2022-07-09 00:20:00   13.942  \n",
       "2022-07-09 00:30:00   13.750  \n",
       "2022-07-09 00:40:00   14.038  \n",
       "...                      ...  \n",
       "2022-08-14 10:40:00      NaN  \n",
       "2022-08-14 10:50:00      NaN  \n",
       "2022-08-14 11:00:00      NaN  \n",
       "2022-08-14 11:10:00      NaN  \n",
       "2022-08-14 11:20:00      NaN  \n",
       "\n",
       "[5269 rows x 7 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.iloc[:-4,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93616fa4-c310-4529-b3af-ef7c192ea70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"time\"] = pd.to_datetime(df.dt,format = '%d/%m/%y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1fee2a-cf77-43d4-a3c7-ba3a916d83ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e4012b-f037-40be-8811-0fb2742d2f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcf2a82-0c6e-4578-90b6-debf7becbc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files into list of dataframes\n",
    "# Get minimum length of observations so all data runs through same timeframe\n",
    "# rename columns with logger names, grab only relevant columns\n",
    "mylist = []\n",
    "mylength = []\n",
    "for i in files:\n",
    "    print(i)\n",
    "    try:\n",
    "        a = pd.read_csv(F\"{datadir}/{i}\",header =1)\n",
    "        mylength.append(len(a))\n",
    "        log = i[:7]\n",
    "        a = a.iloc[:,[0,1,2]]\n",
    "        mapping = {a.columns[0]: F\"number_{log}\", a.columns[1]: F'dt_{log}',a.columns[2]:log}\n",
    "        a.rename(columns=mapping,inplace = True)\n",
    "        mylist.append(a)\n",
    "    except:\n",
    "        \"not a real file\"\n",
    "min_length= min(mylength)\n",
    "\n",
    "## concatenate along columns to create new df.\n",
    "df = pd.concat(newlist,axis = 1)\n",
    "\n",
    "# convert date time\n",
    "df[\"time\"] = pd.to_datetime(df.dt_Log_201,format = '%d/%m/%y %H:%M:%S')\n",
    "\n",
    "#mark days\n",
    "df[\"mon_day\"] = df.time.dt.to_period(\"d\")\n",
    "\n",
    "## extract only relevant columns data\n",
    "cols = ['mon_day','time']\n",
    "for i in df.columns:\n",
    "    if i[:3] == \"Log\":\n",
    "        cols.append(i)\n",
    "temps_ = df[cols].copy()\n",
    "\n",
    "# write to csv\n",
    "temps_.to_csv(F\"{writedir}/alldata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d1d4f9-f243-4d1c-8271-d2070cf07116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lineplot of all values\n",
    "log_cols = [ x for x in temps_.columns if x[:3] == \"Log\" ]\n",
    "log_cols.append(\"time\")\n",
    "mydata = temps_[log_cols]\n",
    "mydata_m = mydata.melt('time', var_name='logger', value_name='temps')\n",
    "fix,axs = plt.subplots(figsize = (16,16))\n",
    "sns.lineplot(data=mydata_m, x=mydata_m.time.astype(str),y='temps',hue = 'logger')\n",
    "axs.set_title(\"Temperature values July 08th - August 10th\")\n",
    "plt.xlabel(\"Day\")\n",
    "plt.ylabel(\"Mean daily temperature (°C)\")\n",
    "plt.title(\"Daily temperature means 15-05.2018 - 15-09.2018\")\n",
    "loc = AutoLocator()\n",
    "axs.xaxis.set_major_locator(loc)\n",
    "plt.tight_layout()\n",
    "plt.savefig(F'{figdir}/biel-july-all-data.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca3cf2a-c7ea-40ce-b030-6d6b407ddea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## aggregate by daily values (max, min, mean, var)\n",
    "log_cols = [ x for x in temps_.columns if x[:3] == \"Log\" ]\n",
    "\n",
    "#create dictionaries for use in aggregation\n",
    "maxl = [\"max\"]*loggers\n",
    "minl = [\"min\"]*loggers\n",
    "meanl = [\"mean\"]*loggers\n",
    "varl = [\"var\"]*loggers\n",
    "max_ = dict(zip(log_cols,maxl))\n",
    "min_ = dict(zip(log_cols,minl))\n",
    "mean_ = dict(zip(log_cols,meanl))\n",
    "var_ = dict(zip(log_cols,varl))\n",
    "\n",
    "# agg by daily values\n",
    "daily_max = temps_.groupby([\"mon_day\"]).agg(max_)\n",
    "daily_min = temps_.groupby([\"mon_day\"]).agg(min_)\n",
    "daily_mean = temps_.groupby([\"mon_day\"]).agg(mean_)\n",
    "daily_var = temps_.groupby([\"mon_day\"]).agg(var_)\n",
    "daily_max.reset_index(inplace=True)\n",
    "daily_min.reset_index(inplace=True)\n",
    "daily_mean.reset_index(inplace=True)\n",
    "daily_var.reset_index(inplace=True)\n",
    "log_cols.append(\"mon_day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2352c073-3407-409b-894f-5d77c2fd1863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the max, min, var, and mean temp for each station\n",
    "\n",
    "fig, axs = plt.subplots(2,2,figsize=(14,14))\n",
    "mydata = daily_max[log_cols]\n",
    "mydata_m = mydata.melt('mon_day', var_name='logger', value_name='temps')\n",
    "sns.lineplot(data=mydata_m, x=mydata_m['mon_day'].astype(str),y='temps',hue = 'logger',ax=axs[0,0])\n",
    "axs[0,0].set_title(\"Maximum daily temperature\")\n",
    "axs[0,0].xaxis.set_major_locator(ticker.AutoLocator())\n",
    "mydata = daily_min[log_cols]\n",
    "mydata_m = mydata.melt('mon_day', var_name='logger', value_name='temps')\n",
    "sns.lineplot(data=mydata_m, x=mydata_m['mon_day'].astype(str),y='temps',hue = 'logger',ax = axs[0,1])\n",
    "axs[0,1].set_title(\"Minimum daily temperature\")\n",
    "axs[0,1].xaxis.set_major_locator(ticker.AutoLocator())\n",
    "mydata = daily_mean[log_cols]\n",
    "mydata_m = mydata.melt('mon_day', var_name='logger', value_name='temps')\n",
    "sns.lineplot(data=mydata_m, x=mydata_m['mon_day'].astype(str),y='temps',hue = 'logger',ax = axs[1,0])\n",
    "axs[1,0].set_title(\"Mean daily temperature\")\n",
    "axs[1,0].xaxis.set_major_locator(ticker.AutoLocator())\n",
    "mydata = daily_var[log_cols]\n",
    "mydata_m = mydata.melt('mon_day', var_name='logger', value_name='temps')\n",
    "sns.lineplot(data=mydata_m, x=mydata_m['mon_day'].astype(str),y='temps',hue = 'logger',ax = axs[1,1])\n",
    "axs[1,1].set_title(\"variance of daily temperature\")\n",
    "axs[1,1].xaxis.set_major_locator(ticker.AutoLocator())\n",
    "plt.tight_layout()\n",
    "plt.savefig(F\"{figdir}/all-sensors-stats-biel-2022.png\",bbox_inches='tight', dpi = 200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb87eb2b-05fb-4b0f-bf22-78869294909a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign groups based on features \n",
    "temps_['mean_rural'] = (temps_.Log_206 + temps_.Log_207)/2\n",
    "temps_['mean_urban'] = (temps_.Log_201 + temps_.Log_202 + temps_.Log_203+ temps_.Log_204+ temps_.Log_205)/5\n",
    "temps_['mean_parks'] = (temps_.Log_204 + temps_.Log_205)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f79276-8c76-48ce-89c0-b3312e35176c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new urban mean excluding parks and get overall mean of all logs\n",
    "temps_['mean_urban'] = (temps_.Log_201 + temps_.Log_202 + temps_.Log_203)/3\n",
    "temps_['mean'] = temps_.mean(numeric_only=True,axis = 1)\n",
    "log_cols = [ x for x in temps_.columns if x[:4] == \"mean\" ]\n",
    "\n",
    "# number of groups\n",
    "length = 4\n",
    "\n",
    "#create dictionaries for use in aggregation\n",
    "maxl = [\"max\"]*length\n",
    "minl = [\"min\"]*length\n",
    "meanl = [\"mean\"]*length\n",
    "varl = [\"var\"]*length\n",
    "max_ = dict(zip(log_cols,maxl))\n",
    "min_ = dict(zip(log_cols,minl))\n",
    "mean_ = dict(zip(log_cols,meanl))\n",
    "var_ = dict(zip(log_cols,varl))\n",
    "\n",
    "# agg by daily values\n",
    "daily_max = temps_.groupby([\"mon_day\"]).agg(max_)\n",
    "daily_min = temps_.groupby([\"mon_day\"]).agg(min_)\n",
    "daily_mean = temps_.groupby([\"mon_day\"]).agg(mean_)\n",
    "daily_var = temps_.groupby([\"mon_day\"]).agg(var_)\n",
    "daily_max.reset_index(inplace=True)\n",
    "daily_min.reset_index(inplace=True)\n",
    "daily_mean.reset_index(inplace=True)\n",
    "daily_var.reset_index(inplace=True)\n",
    "log_cols.append(\"mon_day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb250dfa-ca29-426b-a825-f85dc70b6d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the max, min, var, and mean temp for each station\n",
    "fig, axs = plt.subplots(2,2,figsize=(14,14))\n",
    "mydata = daily_max[log_cols]\n",
    "mydata_m = mydata.melt('mon_day', var_name='logger', value_name='temps')\n",
    "a=sns.lineplot(data=mydata_m, x=mydata_m['mon_day'].astype(str),y='temps',hue = 'logger',ax=axs[0,0])\n",
    "axs[0,0].set_title(\"Maximum daily temperature\")\n",
    "axs[0,0].xaxis.set_major_locator(ticker.AutoLocator())\n",
    "mydata = daily_min[log_cols]\n",
    "mydata_m = mydata.melt('mon_day', var_name='logger', value_name='temps')\n",
    "sns.lineplot(data=mydata_m, x=mydata_m['mon_day'].astype(str),y='temps',hue = 'logger',ax = axs[0,1])\n",
    "axs[0,1].set_title(\"Minimum daily temperature\")\n",
    "axs[0,1].xaxis.set_major_locator(ticker.AutoLocator())\n",
    "mydata = daily_mean[log_cols]\n",
    "mydata_m = mydata.melt('mon_day', var_name='logger', value_name='temps')\n",
    "sns.lineplot(data=mydata_m, x=mydata_m['mon_day'].astype(str),y='temps',hue = 'logger',ax = axs[1,0])\n",
    "axs[1,0].set_title(\"Mean daily temperature\")\n",
    "axs[1,0].xaxis.set_major_locator(ticker.AutoLocator())\n",
    "mydata = daily_var[log_cols]\n",
    "mydata_m = mydata.melt('mon_day', var_name='logger', value_name='temps')\n",
    "sns.lineplot(data=mydata_m, x=mydata_m['mon_day'].astype(str),y='temps',hue = 'logger',ax = axs[1,1])\n",
    "axs[1,1].set_title(\"variance of daily temperature\")\n",
    "axs[1,1].xaxis.set_major_locator(ticker.AutoLocator())\n",
    "plt.tight_layout()\n",
    "plt.savefig(F\"{figdir}/summary_grouped_biel_2022.png\",bbox_inches='tight', dpi = 200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eede21ae-a42a-46a7-b0bd-ea2b4cd620a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
